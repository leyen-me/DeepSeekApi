import datetime
import os
import re
from flask import Flask, Response, request, stream_with_context
from openai import OpenAI
from flask_cors import CORS
from constans.v3_prompt import build_v3_prompt
from tools import tools
from enum import Enum, auto

class TokenizerState(Enum):
    NORMAL = auto()          # æ­£å¸¸æ–‡æœ¬çŠ¶æ€
    TOOL_START = auto()      # å¯èƒ½æ˜¯<tool>çš„å¼€å§‹
    IN_TOOL = auto()         # åœ¨<tool>æ ‡ç­¾å†…
    TOOL_END = auto()        # å¯èƒ½æ˜¯</tool>çš„å¼€å§‹
    EMPTY_START = auto()     # å¯èƒ½æ˜¯<empty/>çš„å¼€å§‹

def parse_tool_call(tool_content):
    """è§£æå·¥å…·è°ƒç”¨å†…å®¹ï¼Œè¿”å›å‡½æ•°åå’Œå‚æ•°"""
    pattern = r'(\w+)\((.*)\)'
    match = re.match(pattern, tool_content)
    if not match:
        return None, None
    
    func_name = match.group(1)
    args_str = match.group(2)
    
    # ç®€å•è§£æå‚æ•°ï¼ˆå‡è®¾å‚æ•°æ˜¯å­—ç¬¦ä¸²å½¢å¼ï¼‰
    args = [arg.strip().strip('"\'') for arg in args_str.split(',') if arg.strip()]
    return func_name, args

def execute_tool(func_name, args):
    try:
        for tool in tools:
            if tool['name'] == func_name:
                tool_func = tool['function']
                result = tool_func(*args)
                return str(result)
        return f"Error: Tool {func_name} not found"
    except Exception as e:
        return f"Error: {e}"
class StreamTokenizer:
    def __init__(self):
        self.buffer = ""
        self.state = TokenizerState.NORMAL
        self.token_buffer = ""
        self.position = 0
        
    def process_char(self, char):
        """å¤„ç†å•ä¸ªå­—ç¬¦ï¼Œè¿”å›(è¾“å‡ºæ–‡æœ¬, æ˜¯å¦éœ€è¦è¾“å‡º)"""
        if self.state == TokenizerState.NORMAL:
            if char == '<':
                self.state = TokenizerState.TOOL_START
                self.token_buffer = char
                return None, False, False
            return char, True, False
            
        elif self.state == TokenizerState.TOOL_START:
            self.token_buffer += char
            if self.token_buffer == "<tool>":
                self.state = TokenizerState.IN_TOOL
                self.token_buffer = ""  # æ¸…ç©ºbufferå‡†å¤‡æ¥æ”¶å‡½æ•°è°ƒç”¨å†…å®¹
                return None, False, False
            elif self.token_buffer == "<empty":
                self.state = TokenizerState.EMPTY_START
                return None, False, False
            elif len(self.token_buffer) >= 6:  # ä¸æ˜¯ç‰¹æ®Šæ ‡è®°
                self.state = TokenizerState.NORMAL
                result = self.token_buffer
                self.token_buffer = ""
                return result, True, False
            return None, False, False
            
        elif self.state == TokenizerState.IN_TOOL:
            if char == '<' and not self.token_buffer.endswith('</'):
                # å¯èƒ½æ˜¯ç»“æŸæ ‡ç­¾çš„å¼€å§‹
                self.token_buffer += char
                return None, False, False
            elif self.token_buffer.endswith('</') and char == 't':
                self.token_buffer += char
                return None, False, False
            elif self.token_buffer.endswith('</t') and char == 'o':
                self.token_buffer += char
                return None, False, False
            elif self.token_buffer.endswith('</to') and char == 'o':
                self.token_buffer += char
                return None, False, False
            elif self.token_buffer.endswith('</too') and char == 'l':
                self.token_buffer += char
                return None, False, False
            elif self.token_buffer.endswith('</tool') and char == '>':
                # å®Œæ•´çš„å·¥å…·è°ƒç”¨ç»“æŸï¼Œæ‰§è¡Œå‡½æ•°
                tool_content = self.token_buffer[:-6].strip()  # ç§»é™¤</tool>
                func_name, args = parse_tool_call(tool_content)
                if func_name:
                    result = execute_tool(func_name, args)
                    self.state = TokenizerState.NORMAL
                    self.token_buffer = ""
                    return result, True, True
                self.state = TokenizerState.NORMAL
                self.token_buffer = ""
                return None, False, False
            else:
                self.token_buffer += char
                return None, False, False
            
        elif self.state == TokenizerState.EMPTY_START:
            self.token_buffer += char
            if self.token_buffer == "<empty/>":
                self.state = TokenizerState.NORMAL
                self.token_buffer = ""
                return None, False, False
            elif len(self.token_buffer) >= 8:  # ä¸æ˜¯<empty/>
                self.state = TokenizerState.NORMAL
                result = self.token_buffer
                self.token_buffer = ""
                return result, True, False
            return None, False, False
            
        return None, False, False

client = OpenAI(
    base_url='https://api-inference.modelscope.cn/v1/',
    api_key=os.getenv('MODEL_SCOPE_API_KEY'),
)

app = Flask(__name__)
print_mode = False
CORS(app)


def process_stream_response(response, messages, tokenizer):
    output_buffer = ""
    all_buffer = ""
    
    for chunk in response:
        content = chunk.choices[0].delta.content
        if content is None:
            continue
        
        for char in content:
            text, should_output, is_tool = tokenizer.process_char(char)
            if text is not None:
                output_buffer += text

                if not is_tool:
                    all_buffer += text
            
            if should_output and output_buffer:
                if not is_tool:
                    if print_mode:
                        print('------normal------')
                        print(text)
                    yield output_buffer
                output_buffer = ""
            
            if is_tool:
                if print_mode:
                    print('------tool------')
                    print(text)
                messages.append({
                    "role": "assistant",
                    "content": all_buffer
                })
                messages.append({
                    "role": "user",
                    "content": text
                })
                # åˆ›å»ºæ–°çš„å“åº”æµå¹¶ç»§ç»­å¤„ç†
                new_response = client.chat.completions.create(
                    model='deepseek-ai/DeepSeek-V3',
                    messages=messages,
                    stream=True
                )
                yield from process_stream_response(new_response, messages, tokenizer)
                return  # ç»“æŸå½“å‰ç”Ÿæˆå™¨
    
    if output_buffer:
        yield output_buffer


@app.route("/v1/stream", methods=["POST"])
def stream():
    body = request.json
    v3_prompt = build_v3_prompt(tools)
    messages = body.get('messages', [])
    messages.insert(0, {
        "role": "system",
        "content": v3_prompt
    })
    
    def generate(messages):
        response = client.chat.completions.create(
            model='deepseek-ai/DeepSeek-V3',
            messages=messages,
            stream=True
        )
        tokenizer = StreamTokenizer()
        yield from process_stream_response(response, messages, tokenizer)

    return Response(
        stream_with_context(generate(messages)),
        mimetype='text/event-stream'
    )

if __name__ == '__main__':
    print("="*50)
    print("ğŸš€ æœåŠ¡å¯åŠ¨æˆåŠŸ!")
    print(f"ğŸ“¡ æœåŠ¡è¿è¡Œåœ¨: http://0.0.0.0:5000")
    # å½“å‰æ—¶é—´
    print(f"â° å½“å‰æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*50)
    app.run(debug=True, host='0.0.0.0', port=5000)